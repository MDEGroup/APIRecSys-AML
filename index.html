<!DOCTYPE html>
<html lang="en">
<head>
  <title>The ASE paper supporting page</title>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.4.1/css/bootstrap.min.css">
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.4.1/jquery.min.js"></script>
  <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.4.1/js/bootstrap.min.js"></script>
  <script src="https://cdn.jsdelivr.net/gh/google/code-prettify@master/loader/run_prettify.js"></script>
  <style>
    hr.style2 {
      border-top: 3px double #8c8b8b;
    }
    ol.afc li{
      font-family: courier, courier new, serif;
      font-size: 10px
    }
  </style>
</head>
<body>

  <div class="jumbotron text-center">
    <h1>Adversarial Attacks to API Recommender Systems: Time to Wake Up and Smell the Coffee?</h1>
    <p>ASE2021 paper supporting site</p> 
  </div>
  <div class="container-fluid">
    <div class="row">
       

    </div>
    <div class="row">
      <div class="col-sm-12">
        <h3>Abstract</h3>
        Recommender systems in software engineering provide developers with a wide range of valuable items to help them complete their tasks. Among others, API recommender systems have gained momentum in recent years as they became more successful at suggesting API calls or code snippets. While these systems have proven to be effective in terms of prediction accuracy, there has been less attention for what concerns such recommenders' resilience against adversarial attempts.
        In fact, by crafting the recommenders' learning material, e.g., data from large open-source software (OSS) repositories, hostile users may succeed in injecting malicious data, putting at risk the software clients adopting API recommender systems.
        In this paper, we present an empirical investigation of adversarial machine learning techniques and their possible influence on recommender systems.
        The evaluation performed on three state-of-the-art API recommender systems reveals a worrying outcome: all of them are not immune to malicious data. The obtained result triggers the need for effective countermeasures to protect recommender systems against hostile attacks disguised in training data.
      </div>
    
    </div>
   
    <div class=row>
      <div class="col-sm-12">
      <h3>Pages</h3>
        <ol>
          <li><a href="https://ase2021-aml.github.io/APIRecSys/supporting_materials.html">Supporting materials</a></li>
          <li>FOCUS replication packages:
            <ol type="a">
              <li><a href="https://github.com/ASE2021-AML/APIRecSys/tree/master/FOCUS/injector">Focus injector tool</a></li>
              <li><a href="https://github.com/ASE2021-AML/APIRecSys/tree/master/FOCUS/dataset">Fake data</a></li>
              <li><a href="https://github.com/crossminer/FOCUS">Focus Recommender system</a></li>
            </ol>
          </li>
          <li>UPMiner and PAM replication packages:
            <ol type="a">
              <li><a href="https://github.com/ASE2021-AML/APIRecSys/tree/master/UPMiner_PAM/injector">ARFF Injector tool</a></li>
              <li><a href="https://github.com/ASE2021-AML/APIRecSys/tree/master/UPMiner_PAM/dataset">Fake data</a></li>
              <li><a href="https://github.com/mast-group/api-mining">UPMiner and PAM recommender systems</a></li>
            </ol>
          </li>
          <li><a href="https://drive.google.com/file/d/1IBQ77z_OTLhPGTRbwqfR6DN2phPOh-Rz/view?usp=sharing">Paper collection</a></li>
        </ol>
      </div>
    </div>
  </div>
</body>
