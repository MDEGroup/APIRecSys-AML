java/io/PrintStream/println(java.lang.String)	0.8889801
org/apache/hadoop/conf/Configuration/set(java.lang.String,java.lang.String)	0.87897635
org/apache/spark/SparkConf/setAppName(java.lang.String)	0.87897635
org/apache/spark/api/java/AbstractJavaRDDLike/map(org.apache.spark.api.java.function.Function)	0.87897635
org/apache/spark/api/java/AbstractJavaRDDLike/mapToPair(org.apache.spark.api.java.function.PairFunction)	0.87897635
org/apache/spark/api/java/JavaSparkContext/JavaSparkContext(org.apache.spark.SparkConf)	0.87897635
org/apache/spark/api/java/JavaSparkContext/newAPIHadoopFile(java.lang.String,java.lang.Class,java.lang.Class,java.lang.Class,org.apache.hadoop.conf.Configuration)	0.87897635
org/apache/spark/SparkConf/SparkConf()	0.8090518
org/apache/spark/api/java/AbstractJavaRDDLike/count()	0.8090518
org/apache/spark/api/java/AbstractJavaRDDLike/flatMap(org.apache.spark.api.java.function.FlatMapFunction)	0.8090518
org/apache/spark/api/java/JavaRDD/filter(org.apache.spark.api.java.function.Function)	0.8090518
org/apache/spark/sql/Column/$eq$eq$eq(java.lang.Object)	0.8090518
org/apache/spark/sql/Column/equalTo(java.lang.Object)	0.8090518
org/apache/spark/sql/DataFrame/coalesce(int)	0.8090518
org/apache/spark/sql/DataFrame/col(java.lang.String)	0.8090518
org/apache/spark/sql/DataFrame/count()	0.8090518
org/apache/spark/sql/DataFrame/distinct()	0.8090518
org/apache/spark/sql/DataFrame/drop(java.lang.String)	0.8090518
org/apache/spark/sql/DataFrame/drop(org.apache.spark.sql.Column)	0.8090518
org/apache/spark/sql/DataFrame/filter(org.apache.spark.sql.Column)	0.8090518
org/apache/spark/sql/DataFrame/javaRDD()	0.8090518
org/apache/spark/sql/DataFrame/join(org.apache.spark.sql.DataFrame,org.apache.spark.sql.Column)	0.8090518
org/apache/spark/sql/DataFrame/printSchema()	0.8090518
org/apache/spark/sql/DataFrame/registerTempTable(java.lang.String)	0.8090518
org/apache/spark/sql/DataFrame/select(java.lang.String,java.lang.String[])	0.8090518
org/apache/spark/sql/DataFrame/show()	0.8090518
org/apache/spark/sql/DataFrame/show(int)	0.8090518
org/apache/spark/sql/DataFrameReader/parquet(java.lang.String[])	0.8090518
org/apache/spark/sql/DataFrameWriter/format(java.lang.String)	0.8090518
org/apache/spark/sql/DataFrameWriter/mode(org.apache.spark.sql.SaveMode)	0.8090518
org/apache/spark/sql/DataFrameWriter/parquet(java.lang.String)	0.8090518
org/apache/spark/sql/DataFrameWriter/save(java.lang.String)	0.8090518
org/apache/spark/sql/SQLContext/read()	0.8090518
org/apache/spark/sql/SQLContext/sql(java.lang.String)	0.8090518
org/apache/spark/sql/types/DataTypes/createStructField(java.lang.String,org.apache.spark.sql.types.DataType,boolean)	0.8090518
org/apache/spark/sql/types/StructType/StructType(org.apache.spark.sql.types.StructField[])	0.8090518
java/lang/System/exit(int)	0.749131
a4example/BadRecordCount/main(java/lang/String[])/$anonymous1/()	0.73912734
a4example/BadRecordCount/main(java/lang/String[])/$anonymous2/()	0.73912734
a4example/BadRecordCount/main(java/lang/String[])/$anonymous3/()	0.73912734
a4example/BadRecordCount/main(java/lang/String[])/$anonymous4/()	0.73912734
code/spark/SparkSQL/main(java/lang/String[])/$anonymous1/()	0.73912734
code/spark/SparkSQL/main(java/lang/String[])/$anonymous2/()	0.73912734
code/spark/SparkSQL/main(java/lang/String[])/$anonymous3/()	0.73912734
code/spark/SparkSQL/main(java/lang/String[])/$anonymous4/()	0.73912734
code/spark/SparkSQL/main(java/lang/String[])/$anonymous5/()	0.73912734
java/io/FileWriter/FileWriter(java.lang.String)	0.73912734
java/io/PrintWriter/PrintWriter(java.io.Writer)	0.73912734
java/io/PrintWriter/close()	0.73912734
java/io/PrintWriter/println(java.lang.String)	0.73912734
java/lang/Throwable/getMessage()	0.73912734
org/apache/spark/SparkConf/setMaster(java.lang.String)	0.73912734
org/apache/spark/api/java/AbstractJavaRDDLike/collect()	0.73912734
org/apache/spark/api/java/AbstractJavaRDDLike/reduce(org.apache.spark.api.java.function.Function2)	0.73912734
org/apache/spark/api/java/AbstractJavaRDDLike/saveAsTextFile(java.lang.String)	0.73912734
org/apache/spark/api/java/JavaPairRDD/coalesce(int)	0.73912734
org/apache/spark/api/java/JavaPairRDD/values()	0.73912734
org/apache/spark/api/java/JavaSparkContext/stop()	0.73912734
org/apache/spark/sql/DataFrame/write()	0.73912734
org/apache/spark/sql/SQLContext/SQLContext(org.apache.spark.api.java.JavaSparkContext)	0.73912734
org/apache/spark/sql/SQLContext/createDataFrame(org.apache.spark.api.java.JavaRDD,org.apache.spark.sql.types.StructType)	0.73912734
scala/Tuple2/_1()	0.73912734
scala/Tuple2/_2()	0.73912734
code/spark/SparkSQLPractice/main(java/lang/String[])/$anonymous1/()	0.7391273
code/spark/SparkSQLPractice/main(java/lang/String[])/$anonymous2/()	0.7391273
code/spark/SparkSQLPractice/main(java/lang/String[])/$anonymous3/()	0.7391273
code/spark/SparkSQLPractice/main(java/lang/String[])/$anonymous4/()	0.7391273
code/spark/SparkSQLPractice/main(java/lang/String[])/$anonymous5/()	0.7391273
org/apache/hadoop/fs/Path/Path(java.lang.String)	0.6792065
org/apache/hadoop/mapreduce/Job/Job(org.apache.hadoop.conf.Configuration,java.lang.String)	0.6792065
org/apache/hadoop/mapreduce/Job/setInputFormatClass(java.lang.Class)	0.6792065
org/apache/hadoop/mapreduce/Job/setJarByClass(java.lang.Class)	0.6792065
org/apache/hadoop/mapreduce/Job/setMapperClass(java.lang.Class)	0.6792065
org/apache/hadoop/mapreduce/Job/setOutputFormatClass(java.lang.Class)	0.6792065
org/apache/hadoop/mapreduce/Job/setOutputKeyClass(java.lang.Class)	0.6792065
org/apache/hadoop/mapreduce/Job/setOutputValueClass(java.lang.Class)	0.6792065
org/apache/hadoop/mapreduce/Job/setReducerClass(java.lang.Class)	0.6792065
org/apache/hadoop/mapreduce/Job/waitForCompletion(boolean)	0.6792065
org/apache/hadoop/mapreduce/lib/input/FileInputFormat/addInputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)	0.6792065
org/apache/hadoop/mapreduce/lib/output/FileOutputFormat/setOutputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path)	0.6792065
java/io/BufferedReader/BufferedReader(java.io.Reader)	0.6692028
java/io/BufferedReader/close()	0.6692028
java/io/BufferedReader/readLine()	0.6692028
java/io/DataInput/readInt()	0.6692028
java/io/DataInput/readLong()	0.6692028
java/io/DataInputStream/readUTF()	0.6692028
java/io/DataOutput/writeInt(int)	0.6692028
java/io/DataOutput/writeLong(long)	0.6692028
java/io/DataOutputStream/writeUTF(java.lang.String)	0.6692028
java/io/FileReader/FileReader(java.lang.String)	0.6692028
java/io/FilterInputStream/close()	0.6692028
java/io/PrintWriter/PrintWriter(java.lang.String)	0.6692028
java/lang/Integer/compareTo(java.lang.Integer)	0.6692028
java/lang/Integer/parseInt(java.lang.String)	0.6692028
java/lang/Iterable/iterator()	0.6692028
java/lang/String/compareTo(java.lang.String)	0.6692028
java/lang/String/equals(java.lang.Object)	0.6692028
java/lang/String/hashCode()	0.6692028
java/lang/String/split(java.lang.String)	0.6692028
java/lang/String/substring(int)	0.6692028
java/lang/StringBuilder/StringBuilder()	0.6692028
java/lang/StringBuilder/append(java.lang.Object)	0.6692028
java/lang/StringBuilder/append(java.lang.String)	0.6692028
java/lang/StringBuilder/toString()	0.6692028
java/lang/Throwable/printStackTrace()	0.6692028
java/net/URI/URI(java.lang.String)	0.6692028
java/util/ArrayList/ArrayList()	0.6692028
java/util/Hashtable/get(java.lang.Object)	0.6692028
java/util/Hashtable/put(K,V)	0.6692028
java/util/Iterator/hasNext()	0.6692028
java/util/Iterator/next()	0.6692028
java/util/List/add(E)	0.6692028
java/util/StringTokenizer/StringTokenizer(java.lang.String)	0.6692028
java/util/StringTokenizer/hasMoreTokens()	0.6692028
java/util/StringTokenizer/nextToken()	0.6692028
java/util/regex/Matcher/find()	0.6692028
java/util/regex/Matcher/group(int)	0.6692028
java/util/regex/Pattern/compile(java.lang.String)	0.6692028
java/util/regex/Pattern/matcher(java.lang.CharSequence)	0.6692028
org/apache/hadoop/conf/Configuration/get(java.lang.String)	0.6692028
org/apache/hadoop/conf/Configuration/setBoolean(java.lang.String,boolean)	0.6692028
org/apache/hadoop/conf/Configured/getConf()	0.6692028
org/apache/hadoop/filecache/DistributedCache/addCacheFile(java.net.URI,org.apache.hadoop.conf.Configuration)	0.6692028
org/apache/hadoop/filecache/DistributedCache/createSymlink(org.apache.hadoop.conf.Configuration)	0.6692028
org/apache/hadoop/filecache/DistributedCache/getLocalCacheFiles(org.apache.hadoop.conf.Configuration)	0.6692028
org/apache/hadoop/fs/FSDataOutputStream/close()	0.6692028
org/apache/hadoop/fs/FileSystem/create(org.apache.hadoop.fs.Path)	0.6692028
org/apache/hadoop/fs/FileSystem/delete(org.apache.hadoop.fs.Path,boolean)	0.6692028
org/apache/hadoop/fs/FileSystem/exists(org.apache.hadoop.fs.Path)	0.6692028
org/apache/hadoop/fs/FileSystem/get(org.apache.hadoop.conf.Configuration)	0.6692028
org/apache/hadoop/fs/FileSystem/open(org.apache.hadoop.fs.Path)	0.6692028
org/apache/hadoop/fs/Path/Path(org.apache.hadoop.fs.Path,java.lang.String)	0.6692028
org/apache/hadoop/fs/Path/getFileSystem(org.apache.hadoop.conf.Configuration)	0.6692028
org/apache/hadoop/fs/Path/makeQualified(org.apache.hadoop.fs.FileSystem)	0.6692028
org/apache/hadoop/fs/Path/toString()	0.6692028
org/apache/hadoop/fs/Path/toUri()	0.6692028
org/apache/hadoop/io/IntWritable/IntWritable()	0.6692028
org/apache/hadoop/io/IntWritable/IntWritable(int)	0.6692028
org/apache/hadoop/io/IntWritable/equals(java.lang.Object)	0.6692028
org/apache/hadoop/io/IntWritable/get()	0.6692028
org/apache/hadoop/io/IntWritable/set(int)	0.6692028
org/apache/hadoop/io/LongWritable/LongWritable()	0.6692028
org/apache/hadoop/io/LongWritable/LongWritable(long)	0.6692028
org/apache/hadoop/io/MapFile/Reader/get(org.apache.hadoop.io.WritableComparable,org.apache.hadoop.io.Writable)	0.6692028
org/apache/hadoop/io/MapFile/Reader/next(org.apache.hadoop.io.WritableComparable,org.apache.hadoop.io.Writable)	0.6692028
org/apache/hadoop/io/Text/Text()	0.6692028
org/apache/hadoop/io/Text/Text(java.lang.String)	0.6692028
org/apache/hadoop/io/Text/Text(org.apache.hadoop.io.Text)	0.6692028
org/apache/hadoop/io/Text/set(java.lang.String)	0.6692028
org/apache/hadoop/io/Text/toString()	0.6692028
org/apache/hadoop/io/WritableUtils/readString(java.io.DataInput)	0.6692028
org/apache/hadoop/io/WritableUtils/writeString(java.io.DataOutput,java.lang.String)	0.6692028
org/apache/hadoop/mapred/FileInputFormat/getInputPaths(org.apache.hadoop.mapred.JobConf)	0.6692028
org/apache/hadoop/mapred/FileInputFormat/setInputPaths(org.apache.hadoop.mapred.JobConf,org.apache.hadoop.fs.Path[])	0.6692028
org/apache/hadoop/mapred/FileOutputFormat/setCompressOutput(org.apache.hadoop.mapred.JobConf,boolean)	0.6692028
org/apache/hadoop/mapred/FileOutputFormat/setOutputCompressorClass(org.apache.hadoop.mapred.JobConf,java.lang.Class)	0.6692028
org/apache/hadoop/mapred/FileOutputFormat/setOutputPath(org.apache.hadoop.mapred.JobConf,org.apache.hadoop.fs.Path)	0.6692028
org/apache/hadoop/mapred/JobClient/runJob(org.apache.hadoop.mapred.JobConf)	0.6692028
org/apache/hadoop/mapred/JobConf/JobConf(java.lang.Class)	0.6692028
org/apache/hadoop/mapred/JobConf/JobConf(org.apache.hadoop.conf.Configuration,java.lang.Class)	0.6692028
org/apache/hadoop/mapred/JobConf/setInputFormat(java.lang.Class)	0.6692028
org/apache/hadoop/mapred/JobConf/setJobName(java.lang.String)	0.6692028
org/apache/hadoop/mapred/JobConf/setMapperClass(java.lang.Class)	0.6692028
org/apache/hadoop/mapred/JobConf/setNumReduceTasks(int)	0.6692028
org/apache/hadoop/mapred/JobConf/setOutputFormat(java.lang.Class)	0.6692028
org/apache/hadoop/mapred/JobConf/setOutputKeyClass(java.lang.Class)	0.6692028
org/apache/hadoop/mapred/JobConf/setOutputValueClass(java.lang.Class)	0.6692028
org/apache/hadoop/mapred/JobConf/setPartitionerClass(java.lang.Class)	0.6692028
org/apache/hadoop/mapred/MapFileOutputFormat/getReaders(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.fs.Path,org.apache.hadoop.conf.Configuration)	0.6692028
org/apache/hadoop/mapred/OutputCollector/collect(K,V)	0.6692028
org/apache/hadoop/mapred/Partitioner/getPartition(K2,V2,int)	0.6692028
org/apache/hadoop/mapred/SequenceFileOutputFormat/setOutputCompressionType(org.apache.hadoop.mapred.JobConf,org.apache.hadoop.io.SequenceFile.CompressionType)	0.6692028
org/apache/hadoop/mapred/lib/HashPartitioner/HashPartitioner()	0.6692028
org/apache/hadoop/mapred/lib/InputSampler/RandomSampler/RandomSampler(double,int,int)	0.6692028
org/apache/hadoop/mapred/lib/InputSampler/writePartitionFile(org.apache.hadoop.mapred.JobConf,org.apache.hadoop.mapred.lib.InputSampler.Sampler)	0.6692028
org/apache/hadoop/mapred/lib/TotalOrderPartitioner/setPartitionFile(org.apache.hadoop.mapred.JobConf,org.apache.hadoop.fs.Path)	0.6692028
org/apache/hadoop/mapreduce/Counter/getValue()	0.6692028
org/apache/hadoop/mapreduce/Counter/increment(long)	0.6692028
org/apache/hadoop/mapreduce/Counters/countCounters()	0.6692028
org/apache/hadoop/mapreduce/Counters/findCounter(java.lang.Enum)	0.6692028
org/apache/hadoop/mapreduce/Job/setCombinerClass(java.lang.Class)	0.6692028
org/apache/hadoop/mapreduce/Job/setGroupingComparatorClass(java.lang.Class)	0.6692028
org/apache/hadoop/mapreduce/Job/setMapOutputKeyClass(java.lang.Class)	0.6692028
org/apache/hadoop/mapreduce/Job/setMapOutputValueClass(java.lang.Class)	0.6692028
org/apache/hadoop/mapreduce/Job/setNumReduceTasks(int)	0.6692028
org/apache/hadoop/mapreduce/Job/setPartitionerClass(java.lang.Class)	0.6692028
org/apache/hadoop/mapreduce/Job/setSortComparatorClass(java.lang.Class)	0.6692028
org/apache/hadoop/mapreduce/JobContext/getConfiguration()	0.6692028
org/apache/hadoop/mapreduce/TaskInputOutputContext/getCounter(java.lang.Enum)	0.6692028
org/apache/hadoop/mapreduce/TaskInputOutputContext/write(KEYOUT,VALUEOUT)	0.6692028
org/apache/hadoop/mapreduce/lib/input/MultipleInputs/addInputPath(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path,java.lang.Class,java.lang.Class)	0.6692028
org/apache/hadoop/mapreduce/lib/output/FileOutputFormat/setCompressOutput(org.apache.hadoop.mapreduce.Job,boolean)	0.6692028
org/apache/hadoop/mapreduce/lib/output/FileOutputFormat/setOutputCompressorClass(org.apache.hadoop.mapreduce.Job,java.lang.Class)	0.6692028
org/apache/hadoop/mapreduce/lib/output/MultipleOutputs/MultipleOutputs(org.apache.hadoop.mapreduce.TaskInputOutputContext)	0.6692028
org/apache/hadoop/mapreduce/lib/output/MultipleOutputs/addNamedOutput(org.apache.hadoop.mapreduce.Job,java.lang.String,java.lang.Class,java.lang.Class,java.lang.Class)	0.6692028
org/apache/hadoop/mapreduce/lib/output/MultipleOutputs/close()	0.6692028
org/apache/hadoop/mapreduce/lib/output/MultipleOutputs/write(java.lang.String,K,V)	0.6692028
org/apache/hadoop/mapreduce/lib/output/SequenceFileOutputFormat/setOutputCompressionType(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.io.SequenceFile.CompressionType)	0.6692028
org/apache/hadoop/mrunit/MapDriverBase/runTest()	0.6692028
org/apache/hadoop/mrunit/MapReduceDriverBase/runTest()	0.6692028
org/apache/hadoop/mrunit/ReduceDriverBase/runTest()	0.6692028
org/apache/hadoop/mrunit/mapreduce/MapDriver/newMapDriver(org.apache.hadoop.mapreduce.Mapper)	0.6692028
org/apache/hadoop/mrunit/mapreduce/MapDriver/withConfiguration(org.apache.hadoop.conf.Configuration)	0.6692028
org/apache/hadoop/mrunit/mapreduce/MapDriver/withInput(K1,V1)	0.6692028
org/apache/hadoop/mrunit/mapreduce/MapDriver/withOutput(K2,V2)	0.6692028
org/apache/hadoop/mrunit/mapreduce/MapReduceDriver/getCounters()	0.6692028
org/apache/hadoop/mrunit/mapreduce/MapReduceDriver/newMapReduceDriver(org.apache.hadoop.mapreduce.Mapper,org.apache.hadoop.mapreduce.Reducer)	0.6692028
org/apache/hadoop/mrunit/mapreduce/MapReduceDriver/withConfiguration(org.apache.hadoop.conf.Configuration)	0.6692028
org/apache/hadoop/mrunit/mapreduce/MapReduceDriver/withInput(K1,V1)	0.6692028
org/apache/hadoop/mrunit/mapreduce/MapReduceDriver/withOutput(K3,V3)	0.6692028
org/apache/hadoop/mrunit/mapreduce/ReduceDriver/newReduceDriver(org.apache.hadoop.mapreduce.Reducer)	0.6692028
org/apache/hadoop/mrunit/mapreduce/ReduceDriver/withConfiguration(org.apache.hadoop.conf.Configuration)	0.6692028
org/apache/hadoop/mrunit/mapreduce/ReduceDriver/withInput(K1,java.util.List)	0.6692028
org/apache/hadoop/mrunit/mapreduce/ReduceDriver/withOutput(K2,V2)	0.6692028
org/apache/hadoop/util/GenericOptionsParser/GenericOptionsParser(org.apache.hadoop.conf.Configuration,java.lang.String[])	0.6692028
org/apache/hadoop/util/GenericOptionsParser/getRemainingArgs()	0.6692028
org/apache/hadoop/util/ToolRunner/run(org.apache.hadoop.conf.Configuration,org.apache.hadoop.util.Tool,java.lang.String[])	0.6692028
org/apache/spark/api/java/AbstractJavaRDDLike/flatMapToPair(org.apache.spark.api.java.function.PairFlatMapFunction)	0.6692028
org/apache/spark/api/java/JavaPairRDD/filter(org.apache.spark.api.java.function.Function)	0.6692028
org/apache/spark/api/java/JavaPairRDD/sortByKey(boolean)	0.6692028
org/apache/spark/api/java/JavaSparkContext/textFile(java.lang.String)	0.6692028
scala/Tuple3/Tuple3(T1,T2,T3)	0.6692028
vsu/amm/SparkComputing/SparkComputing()	0.6692028
vsu/amm/SparkComputing/lastGenre()	0.6692028
vsu/amm/SparkComputing/topDiscussedFilms()	0.6692028
vsu/amm/SparkComputing/topGenres()	0.6692028
vsu/amm/SparkComputing/topGenresByUser()	0.6692028
vsu/amm/SparkComputing/topRatedFilms()	0.6692028
vsu/amm/SparkComputing/topRatedGroup()	0.6692028
vsu/amm/SparkComputing/yearComparator/yearComparator()	0.6692028
wikibooks/hadoop/chapter04/WordCountMapper/WordCountMapper()	0.6692028
wikibooks/hadoop/chapter04/WordCountReducer/WordCountReducer()	0.6692028
wikibooks/hadoop/chapter05/ArrivalDelayCountMapper/ArrivalDelayCountMapper()	0.6692028
wikibooks/hadoop/chapter05/DelayCount/DelayCount()	0.6692028
wikibooks/hadoop/chapter05/DelayCountMapperWithCounter/DelayCountMapperWithCounter()	0.6692028
wikibooks/hadoop/chapter05/DelayCountReducer/DelayCountReducer()	0.6692028
wikibooks/hadoop/chapter05/DelayCountWithCounter/DelayCountWithCounter()	0.6692028
wikibooks/hadoop/chapter05/DelayCountWithMultipleOutputs/DelayCountWithMultipleOutputs()	0.6692028
wikibooks/hadoop/chapter06/DateKey/getMonth()	0.6692028
wikibooks/hadoop/chapter06/DateKey/getYear()	0.6692028
wikibooks/hadoop/chapter06/DateKey/setMonth(java.lang.Integer)	0.6692028
wikibooks/hadoop/chapter06/DateKey/setYear(java.lang.String)	0.6692028
wikibooks/hadoop/chapter06/DelayCountWithDateKey/DelayCountWithDateKey()	0.6692028
wikibooks/hadoop/chapter06/MapFileCreator/MapFileCreator()	0.6692028
wikibooks/hadoop/chapter06/SearchValueList/SearchValueList()	0.6692028
wikibooks/hadoop/chapter06/SequenceFileCreator/SequenceFileCreator()	0.6692028
wikibooks/hadoop/chapter06/SequenceFileTotalSort/SequenceFileTotalSort()	0.6692028
wikibooks/hadoop/chapter07/MapSideJoin/MapSideJoin()	0.6692028
wikibooks/hadoop/chapter07/ReduceSideJoin/ReduceSideJoin()	0.6692028
wikibooks/hadoop/chapter07/TaggedKey/getCarrierCode()	0.6692028
wikibooks/hadoop/chapter07/TaggedKey/getTag()	0.6692028
wikibooks/hadoop/chapter07/TaggedKey/setCarrierCode(java.lang.String)	0.6692028
wikibooks/hadoop/chapter07/TaggedKey/setTag(java.lang.Integer)	0.6692028
wikibooks/hadoop/common/AirlinePerformanceParser/AirlinePerformanceParser(org.apache.hadoop.io.Text)	0.6692028
wikibooks/hadoop/common/AirlinePerformanceParser/getArriveDelayTime()	0.6692028
wikibooks/hadoop/common/AirlinePerformanceParser/getDepartureDelayTime()	0.6692028
wikibooks/hadoop/common/AirlinePerformanceParser/getDistance()	0.6692028
wikibooks/hadoop/common/AirlinePerformanceParser/getMonth()	0.6692028
wikibooks/hadoop/common/AirlinePerformanceParser/getUniqueCarrier()	0.6692028
wikibooks/hadoop/common/AirlinePerformanceParser/getYear()	0.6692028
wikibooks/hadoop/common/AirlinePerformanceParser/isArriveDelayAvailable()	0.6692028
wikibooks/hadoop/common/AirlinePerformanceParser/isDepartureDelayAvailable()	0.6692028
wikibooks/hadoop/common/AirlinePerformanceParser/isDistanceAvailable()	0.6692028
wikibooks/hadoop/common/CarrierCodeParser/CarrierCodeParser(java.lang.String)	0.6692028
wikibooks/hadoop/common/CarrierCodeParser/CarrierCodeParser(org.apache.hadoop.io.Text)	0.6692028
wikibooks/hadoop/common/CarrierCodeParser/getCarrierCode()	0.6692028
wikibooks/hadoop/common/CarrierCodeParser/getCarrierName()	0.6692028
