code/spark/SparkSQLPractice/main(java.lang.String[])#org/apache/spark/sql/SQLContext/SQLContext(org.apache.spark.api.java.JavaSparkContext)
code/spark/SparkSQLPractice/main(java.lang.String[])#org/apache/spark/SparkConf/setMaster(java.lang.String)
code/spark/SparkSQLPractice/main(java.lang.String[])#org/apache/spark/sql/DataFrame/write()
code/spark/SparkSQLPractice/main(java.lang.String[])#org/apache/spark/api/java/JavaPairRDD/values()
code/spark/SparkSQLPractice/main(java.lang.String[])#org/apache/spark/sql/SQLContext/createDataFrame(org.apache.spark.api.java.JavaRDD,org.apache.spark.sql.types.StructType)
code/spark/SparkSQLPractice/main(java.lang.String[])#org/apache/spark/SparkConf/SparkConf()
code/spark/SparkSQLPractice/main(java.lang.String[])#org/apache/spark/sql/DataFrame/distinct()
code/spark/SparkSQLPractice/main(java.lang.String[])#org/apache/spark/sql/DataFrameWriter/format(java.lang.String)
code/spark/SparkSQLPractice/main(java.lang.String[])#org/apache/spark/api/java/AbstractJavaRDDLike/count()
code/spark/SparkSQLPractice/main(java.lang.String[])#org/apache/spark/sql/DataFrame/drop(java.lang.String)
code/spark/SparkSQLPractice/main(java.lang.String[])#org/apache/spark/api/java/AbstractJavaRDDLike/mapToPair(org.apache.spark.api.java.function.PairFunction)
code/spark/SparkSQLPractice/main(java.lang.String[])#org/apache/spark/sql/DataFrameWriter/mode(org.apache.spark.sql.SaveMode)
code/spark/SparkSQLPractice/main(java.lang.String[])#org/apache/spark/sql/DataFrame/coalesce(int)
code/spark/SparkSQLPractice/main(java.lang.String[])#org/apache/spark/sql/DataFrame/col(java.lang.String)
code/spark/SparkSQLPractice/main(java.lang.String[])#org/apache/spark/api/java/JavaPairRDD/reduceByKey(org.apache.spark.api.java.function.Function2)
code/spark/SparkSQLPractice/main(java.lang.String[])#org/apache/spark/sql/DataFrame/filter(org.apache.spark.sql.Column)
code/spark/SparkSQLPractice/main(java.lang.String[])#org/apache/spark/sql/SQLContext/sql(java.lang.String)
code/spark/SparkSQLPractice/main(java.lang.String[])#org/apache/spark/api/java/JavaSparkContext/newAPIHadoopFile(java.lang.String,java.lang.Class,java.lang.Class,java.lang.Class,org.apache.hadoop.conf.Configuration)
code/spark/SparkSQLPractice/main(java.lang.String[])#org/apache/spark/sql/types/StructType/StructType(org.apache.spark.sql.types.StructField[])
code/spark/SparkSQLPractice/main(java.lang.String[])#org/apache/hadoop/conf/Configuration/Configuration()
code/spark/SparkSQLPractice/main(java.lang.String[])#org/apache/spark/sql/DataFrameWriter/parquet(java.lang.String)
code/spark/SparkSQLPractice/main(java.lang.String[])#org/apache/spark/sql/Column/equalTo(java.lang.Object)
code/spark/SparkSQLPractice/main(java.lang.String[])#org/apache/spark/api/java/JavaRDD/filter(org.apache.spark.api.java.function.Function)
code/spark/SparkSQLPractice/main(java.lang.String[])#java/io/PrintStream/println(java.lang.String)
code/spark/SparkSQLPractice/main(java.lang.String[])#org/apache/spark/api/java/JavaSparkContext/JavaSparkContext(org.apache.spark.SparkConf)
code/spark/SparkSQLPractice/main(java.lang.String[])#org/apache/spark/sql/DataFrame/show(int)
code/spark/SparkSQLPractice/main(java.lang.String[])#org/apache/spark/sql/DataFrame/drop(org.apache.spark.sql.Column)
code/spark/SparkSQLPractice/main(java.lang.String[])#org/apache/spark/sql/Column/$eq$eq$eq(java.lang.Object)
code/spark/SparkSQLPractice/main(java.lang.String[])#org/apache/spark/api/java/AbstractJavaRDDLike/map(org.apache.spark.api.java.function.Function)
code/spark/SparkSQLPractice/main(java.lang.String[])#org/apache/spark/sql/DataFrame/select(java.lang.String,java.lang.String[])
code/spark/SparkSQLPractice/main(java.lang.String[])#org/apache/spark/sql/DataFrame/show()
code/spark/SparkSQLPractice/main(java.lang.String[])#org/apache/hadoop/conf/Configuration/set(java.lang.String,java.lang.String)
code/spark/SparkSQLPractice/main(java.lang.String[])#org/apache/spark/sql/DataFrame/join(org.apache.spark.sql.DataFrame,org.apache.spark.sql.Column)
code/spark/SparkSQLPractice/main(java.lang.String[])#org/apache/spark/api/java/AbstractJavaRDDLike/flatMap(org.apache.spark.api.java.function.FlatMapFunction)
code/spark/SparkSQLPractice/main(java.lang.String[])#org/apache/spark/sql/types/DataTypes/createStructField(java.lang.String,org.apache.spark.sql.types.DataType,boolean)
code/spark/SparkSQLPractice/main(java.lang.String[])#org/apache/spark/sql/DataFrame/printSchema()
code/spark/SparkSQLPractice/main(java.lang.String[])#code/spark/SparkSQLPractice/main(java/lang/String[])/$anonymous5/()
code/spark/SparkSQLPractice/main(java.lang.String[])#code/spark/SparkSQLPractice/main(java/lang/String[])/$anonymous4/()
code/spark/SparkSQLPractice/main(java.lang.String[])#org/apache/spark/sql/DataFrame/count()
code/spark/SparkSQLPractice/main(java.lang.String[])#org/apache/spark/sql/DataFrame/javaRDD()
code/spark/SparkSQLPractice/main(java.lang.String[])#org/apache/spark/sql/DataFrameReader/parquet(java.lang.String[])
code/spark/SparkSQLPractice/main(java.lang.String[])#code/spark/SparkSQLPractice/main(java/lang/String[])/$anonymous3/()
code/spark/SparkSQLPractice/main(java.lang.String[])#org/apache/spark/sql/SQLContext/read()
code/spark/SparkSQLPractice/main(java.lang.String[])#org/apache/spark/sql/DataFrameWriter/save(java.lang.String)
code/spark/SparkSQLPractice/main(java.lang.String[])#code/spark/SparkSQLPractice/main(java/lang/String[])/$anonymous2/()
code/spark/SparkSQLPractice/main(java.lang.String[])#org/apache/spark/SparkConf/setAppName(java.lang.String)
code/spark/SparkSQLPractice/main(java.lang.String[])#code/spark/SparkSQLPractice/main(java/lang/String[])/$anonymous1/()
code/spark/SparkSQLPractice/main(java.lang.String[])#org/apache/spark/sql/DataFrame/registerTempTable(java.lang.String)
code/spark/SparkSQL/main(java.lang.String[])#org/apache/spark/sql/SQLContext/SQLContext(org.apache.spark.api.java.JavaSparkContext)
code/spark/SparkSQL/main(java.lang.String[])#org/apache/spark/SparkConf/setMaster(java.lang.String)
code/spark/SparkSQL/main(java.lang.String[])#org/apache/spark/sql/DataFrame/write()
code/spark/SparkSQL/main(java.lang.String[])#org/apache/spark/api/java/JavaPairRDD/values()
code/spark/SparkSQL/main(java.lang.String[])#org/apache/spark/sql/SQLContext/createDataFrame(org.apache.spark.api.java.JavaRDD,org.apache.spark.sql.types.StructType)
code/spark/SparkSQL/main(java.lang.String[])#org/apache/spark/SparkConf/SparkConf()
code/spark/SparkSQL/main(java.lang.String[])#org/apache/spark/sql/DataFrame/distinct()
code/spark/SparkSQL/main(java.lang.String[])#org/apache/spark/sql/DataFrameWriter/format(java.lang.String)
code/spark/SparkSQL/main(java.lang.String[])#org/apache/spark/api/java/AbstractJavaRDDLike/count()
code/spark/SparkSQL/main(java.lang.String[])#org/apache/spark/sql/DataFrame/printSchema()
code/spark/SparkSQL/main(java.lang.String[])#org/apache/spark/sql/DataFrame/count()
code/spark/SparkSQL/main(java.lang.String[])#org/apache/spark/sql/DataFrameWriter/save(java.lang.String)
code/spark/SparkSQL/main(java.lang.String[])#code/spark/SparkSQL/main(java/lang/String[])/$anonymous5/()
code/spark/SparkSQL/main(java.lang.String[])#code/spark/SparkSQL/main(java/lang/String[])/$anonymous4/()
code/spark/SparkSQL/main(java.lang.String[])#code/spark/SparkSQL/main(java/lang/String[])/$anonymous3/()
code/spark/SparkSQL/main(java.lang.String[])#org/apache/spark/sql/DataFrameWriter/mode(org.apache.spark.sql.SaveMode)
code/spark/SparkSQL/main(java.lang.String[])#org/apache/spark/sql/DataFrame/coalesce(int)
code/spark/SparkSQL/main(java.lang.String[])#org/apache/spark/sql/DataFrame/col(java.lang.String)
code/spark/SparkSQL/main(java.lang.String[])#org/apache/spark/api/java/JavaPairRDD/reduceByKey(org.apache.spark.api.java.function.Function2)
code/spark/SparkSQL/main(java.lang.String[])#org/apache/spark/sql/DataFrame/filter(org.apache.spark.sql.Column)
code/spark/SparkSQL/main(java.lang.String[])#org/apache/spark/sql/SQLContext/sql(java.lang.String)
code/spark/SparkSQL/main(java.lang.String[])#org/apache/spark/api/java/JavaSparkContext/newAPIHadoopFile(java.lang.String,java.lang.Class,java.lang.Class,java.lang.Class,org.apache.hadoop.conf.Configuration)
code/spark/SparkSQL/main(java.lang.String[])#org/apache/spark/sql/types/StructType/StructType(org.apache.spark.sql.types.StructField[])
code/spark/SparkSQL/main(java.lang.String[])#org/apache/hadoop/conf/Configuration/Configuration()
code/spark/SparkSQL/main(java.lang.String[])#org/apache/spark/sql/DataFrameWriter/parquet(java.lang.String)
code/spark/SparkSQL/main(java.lang.String[])#org/apache/spark/sql/Column/equalTo(java.lang.Object)
code/spark/SparkSQL/main(java.lang.String[])#org/apache/spark/api/java/JavaRDD/filter(org.apache.spark.api.java.function.Function)
code/spark/SparkSQL/main(java.lang.String[])#java/io/PrintStream/println(java.lang.String)
code/spark/SparkSQL/main(java.lang.String[])#org/apache/spark/api/java/JavaSparkContext/JavaSparkContext(org.apache.spark.SparkConf)
code/spark/SparkSQL/main(java.lang.String[])#org/apache/spark/sql/DataFrame/show(int)
code/spark/SparkSQL/main(java.lang.String[])#org/apache/spark/sql/DataFrame/drop(org.apache.spark.sql.Column)
code/spark/SparkSQL/main(java.lang.String[])#org/apache/spark/sql/Column/$eq$eq$eq(java.lang.Object)
code/spark/SparkSQL/main(java.lang.String[])#org/apache/spark/api/java/AbstractJavaRDDLike/map(org.apache.spark.api.java.function.Function)
code/spark/SparkSQL/main(java.lang.String[])#org/apache/spark/sql/DataFrame/select(java.lang.String,java.lang.String[])
code/spark/SparkSQL/main(java.lang.String[])#org/apache/spark/sql/DataFrame/show()
code/spark/SparkSQL/main(java.lang.String[])#org/apache/hadoop/conf/Configuration/set(java.lang.String,java.lang.String)
code/spark/SparkSQL/main(java.lang.String[])#org/apache/spark/sql/DataFrame/join(org.apache.spark.sql.DataFrame,org.apache.spark.sql.Column)
code/spark/SparkSQL/main(java.lang.String[])#org/apache/spark/api/java/AbstractJavaRDDLike/flatMap(org.apache.spark.api.java.function.FlatMapFunction)
code/spark/SparkSQL/main(java.lang.String[])#org/apache/spark/sql/types/DataTypes/createStructField(java.lang.String,org.apache.spark.sql.types.DataType,boolean)
code/spark/SparkSQL/main(java.lang.String[])#org/apache/spark/sql/SQLContext/read()
code/spark/SparkSQL/main(java.lang.String[])#org/apache/spark/sql/DataFrame/javaRDD()
code/spark/SparkSQL/main(java.lang.String[])#org/apache/spark/sql/DataFrameReader/parquet(java.lang.String[])
code/spark/SparkSQL/main(java.lang.String[])#org/apache/spark/SparkConf/setAppName(java.lang.String)
code/spark/SparkSQL/main(java.lang.String[])#org/apache/spark/sql/DataFrame/registerTempTable(java.lang.String)
code/spark/SparkSQL/main(java.lang.String[])#org/apache/spark/sql/DataFrame/drop(java.lang.String)
code/spark/SparkSQL/main(java.lang.String[])#code/spark/SparkSQL/main(java/lang/String[])/$anonymous2/()
code/spark/SparkSQL/main(java.lang.String[])#code/spark/SparkSQL/main(java/lang/String[])/$anonymous1/()
code/spark/SparkSQL/main(java.lang.String[])#org/apache/spark/api/java/AbstractJavaRDDLike/mapToPair(org.apache.spark.api.java.function.PairFunction)
a4example/BadRecordCount/main(java.lang.String[])#org/apache/spark/api/java/JavaPairRDD/reduceByKey(org.apache.spark.api.java.function.Function2)
a4example/BadRecordCount/main(java.lang.String[])#a4example/BadRecordCount/main(java/lang/String[])/$anonymous4/()
a4example/BadRecordCount/main(java.lang.String[])#a4example/BadRecordCount/main(java/lang/String[])/$anonymous3/()
a4example/BadRecordCount/main(java.lang.String[])#scala/Tuple2/_1()
a4example/BadRecordCount/main(java.lang.String[])#org/apache/spark/api/java/JavaPairRDD/coalesce(int)
a4example/BadRecordCount/main(java.lang.String[])#org/apache/spark/SparkConf/setAppName(java.lang.String)
a4example/BadRecordCount/main(java.lang.String[])#java/io/PrintWriter/println(java.lang.String)
a4example/BadRecordCount/main(java.lang.String[])#org/apache/spark/api/java/AbstractJavaRDDLike/mapToPair(org.apache.spark.api.java.function.PairFunction)
a4example/BadRecordCount/main(java.lang.String[])#org/apache/spark/api/java/AbstractJavaRDDLike/reduce(org.apache.spark.api.java.function.Function2)
a4example/BadRecordCount/main(java.lang.String[])#a4example/BadRecordCount/main(java/lang/String[])/$anonymous2/()
a4example/BadRecordCount/main(java.lang.String[])#org/apache/spark/api/java/JavaSparkContext/newAPIHadoopFile(java.lang.String,java.lang.Class,java.lang.Class,java.lang.Class,org.apache.hadoop.conf.Configuration)
a4example/BadRecordCount/main(java.lang.String[])#a4example/BadRecordCount/main(java/lang/String[])/$anonymous1/()
a4example/BadRecordCount/main(java.lang.String[])#org/apache/spark/api/java/AbstractJavaRDDLike/saveAsTextFile(java.lang.String)
a4example/BadRecordCount/main(java.lang.String[])#org/apache/hadoop/conf/Configuration/Configuration()
a4example/BadRecordCount/main(java.lang.String[])#java/io/PrintStream/println(java.lang.String)
a4example/BadRecordCount/main(java.lang.String[])#org/apache/spark/api/java/JavaSparkContext/JavaSparkContext(org.apache.spark.SparkConf)
a4example/BadRecordCount/main(java.lang.String[])#java/io/PrintWriter/PrintWriter(java.io.Writer)
a4example/BadRecordCount/main(java.lang.String[])#java/io/PrintWriter/close()
a4example/BadRecordCount/main(java.lang.String[])#org/apache/spark/api/java/JavaSparkContext/stop()
a4example/BadRecordCount/main(java.lang.String[])#scala/Tuple2/_2()
a4example/BadRecordCount/main(java.lang.String[])#org/apache/spark/api/java/AbstractJavaRDDLike/map(org.apache.spark.api.java.function.Function)
a4example/BadRecordCount/main(java.lang.String[])#org/apache/spark/SparkConf/SparkConf()
a4example/BadRecordCount/main(java.lang.String[])#org/apache/spark/api/java/AbstractJavaRDDLike/collect()
a4example/BadRecordCount/main(java.lang.String[])#java/lang/Throwable/getMessage()
a4example/BadRecordCount/main(java.lang.String[])#org/apache/hadoop/conf/Configuration/set(java.lang.String,java.lang.String)
a4example/BadRecordCount/main(java.lang.String[])#java/lang/System/exit(int)
a4example/BadRecordCount/main(java.lang.String[])#java/io/FileWriter/FileWriter(java.lang.String)
a4example/Util/parseTweet(java.lang.String)#java/util/regex/Matcher/group(int)
a4example/Util/parseTweet(java.lang.String)#java/util/ArrayList/ArrayList()
a4example/Util/parseTweet(java.lang.String)#scala/Tuple3/Tuple3(T1,T2,T3)
a4example/Util/parseTweet(java.lang.String)#java/util/List/add(E)
a4example/Util/parseTweet(java.lang.String)#java/util/regex/Matcher/find()
a4example/Util/parseTweet(java.lang.String)#java/util/regex/Pattern/matcher(java.lang.CharSequence)
a4example/Util/writeGraph(java.util.List,java.lang.String)#java/io/PrintStream/println(java.lang.String)
a4example/Util/writeGraph(java.util.List,java.lang.String)#java/io/PrintWriter/close()
a4example/Util/writeGraph(java.util.List,java.lang.String)#scala/Tuple2/_1()
a4example/Util/writeGraph(java.util.List,java.lang.String)#scala/Tuple2/_2()
a4example/Util/writeGraph(java.util.List,java.lang.String)#java/io/PrintWriter/PrintWriter(java.lang.String)
a4example/Util/writeGraph(java.util.List,java.lang.String)#java/io/PrintWriter/println(java.lang.String)
a4example/Util/hasHashtag(java.lang.String,java.lang.String)#java/util/regex/Pattern/compile(java.lang.String)
a4example/Util/hasHashtag(java.lang.String,java.lang.String)#java/util/regex/Matcher/find()
a4example/Util/hasHashtag(java.lang.String,java.lang.String)#java/util/regex/Pattern/matcher(java.lang.CharSequence)
